
import numpy as np
import tensorflow as tf
class Vectorize:
    def __init__(self,col,tokenize):
        self.col=[i.strip() for i in col]
        self.tokenize=tokenize
        
    def tokenize(self):
        self.tokenize.fit_on_texts(self.col)
        self.tokens=self.tokenize.texts_to_sequences(self.col)
        return self.tokenize.word_index,self.tokenize,self.tokens
    
    def padding(self):
        maxlength=max([len(i) for i in self.tokens])
        self.padded=tf.keras.preprocessing.sequence.pad_sequences(self.tokens,maxlength)
        return self.padded
    
    def embedding(self):
        in_dim=len(self.tokenize.word_index)+1
        out_dim=3
        embedding_layer=tf.keras.layers.Embedding(input_dim=in_dim,output_dim=out_dim)
        self.model=tf.keras.models.Sequential()
        self.model.add(embedding_layer)
        self.model.add(tf.keras.layers.LSTM(32))
        self.model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
        self.model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
        return self.model
    
    def train(self):
        history=self.model.fit(self.padded,
                          np.zeros(len(self.padded)),
                          epochs=10,
                          batch_size=32,
                          validation_split=0.2)
        return self.model
    
    def get_vectors(self):
        self.embedding_layer=self.model.layers[0]
        self.embedding_weights=self.embedding_layer.get_weights()[0]
        word_index = self.tokenize.word_index
        self.word_vectors = {}
        for word, index in word_index.items():
            vector = self.embedding_weights[index]
            self.word_vectors[word] = vector
            
        return self.word_vectors
    
    def padded_embedding(self):
        self.embedding_model = tf.keras.layers.Sequential()
        self.embedding_model.add(self.embedding_layer)
        self.embedding_model.add(tf.keras.layers.GlobalAveragePooling1D())
        
        return self.embedding_model
        